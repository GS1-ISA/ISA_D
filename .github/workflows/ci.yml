name: CI (PR)

on:
  pull_request:
  push:
    branches: [ main, master ]

jobs:
  build-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install base tooling
        run: |
          python -m pip install --upgrade pip
          pip install ruff mypy pytest pytest-cov bandit pip-audit radon
      - name: Determine base ref
        id: base
        shell: bash
        run: |
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "branch=${{ github.base_ref }}" >> $GITHUB_OUTPUT
            git fetch origin ${{ github.base_ref }} --depth=1
            echo "sha=$(git rev-parse origin/${{ github.base_ref }})" >> $GITHUB_OUTPUT
          else
            echo "branch=main" >> $GITHUB_OUTPUT
            git fetch origin main --depth=1 || true
            echo "sha=$(git rev-parse origin/main 2>/dev/null || echo HEAD^)" >> $GITHUB_OUTPUT
          fi
      - name: Significance trigger
        id: sig
        run: |
          python scripts/significance_trigger.py --base "${{ steps.base.outputs.sha }}" \
            --threshold-files 15 \
            --threshold-loc 500 \
            --critical ISA_SuperApp/src/pipelines \
            --critical ISA_SuperApp/src/nesy \
            --critical ISA_SuperApp/src/api_server.py \
            --critical ISA_SuperApp/src/utils \
            --critical ISA_SuperApp/schemas \
            --critical ISA_SuperApp/Dockerfile \
            --critical ISA_SuperApp/docker-compose.yml \
            --critical ISA_SuperApp/requirements.txt \
            --critical ISA_SuperApp/requirements-dev.txt \
            --critical infra
          echo "Significance: ${{ steps.sig.outputs.significant }} Reason: ${{ steps.sig.outputs.reason }}"
      - name: Install project dependencies (best-effort)
        continue-on-error: true
        run: |
          if [ -f ISA_SuperApp/requirements.txt ]; then pip install -r ISA_SuperApp/requirements.txt || true; fi
          if [ -f ISA_SuperApp/requirements-dev.txt ]; then pip install -r ISA_SuperApp/requirements-dev.txt || true; fi
      - name: Lint (ruff)
        run: |
          ruff format --check . --output-format=github
          ruff check . --output-format=github
      - name: Typecheck (mypy) — advisory
        continue-on-error: true
        run: |
          mypy ISA_SuperApp/src || true
      - name: Type coverage (mypy linecount report) — artifact
        continue-on-error: true
        run: |
          mypy --linecount-report .mypy_linecount ISA_SuperApp/src || true
          if [ -f .mypy_linecount/index.txt ]; then echo '--- mypy linecount summary ---'; cat .mypy_linecount/index.txt || true; fi
      - name: Policy lint (advisory)
        continue-on-error: true
        run: |
          python scripts/policy_lint.py || true
      - name: Upload type report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mypy_linecount_${{ matrix.python-version }}
          path: .mypy_linecount
      - name: Tests (pytest) — advisory
        continue-on-error: true
        run: |
          cd ISA_SuperApp && pytest -q || true
      - name: Coverage XML (if tests exist) — artifact
        continue-on-error: true
        run: |
          cd ISA_SuperApp && pytest -q --cov=src --cov-report=xml || true
      - name: Upload coverage.xml
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage_${{ matrix.python-version }}
          path: ISA_SuperApp/coverage.xml
      - name: Combined coverage (advisory)
        continue-on-error: true
        run: |
          rm -f .coverage coverage-total.xml || true
          # Run coverage across app and packages, appending results
          (cd ISA_SuperApp && pytest -q --cov=src --cov-report= --maxfail=1 tests) || true
          (cd packages/orchestrator && pytest -q --cov=src --cov-report= --cov-append tests) || true
          (cd packages/llm && pytest -q --cov=src --cov-report= --cov-append tests) || true
          (cd packages/dspy && pytest -q --cov=src --cov-report= --cov-append tests) || true
          pytest -q --cov=infra/rag --cov-report= --cov-append infra/rag/tests || true
          coverage xml -o coverage-total.xml || true
      - name: Upload combined coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: combined_coverage_${{ matrix.python-version }}
          path: coverage-total.xml
      - name: Coverage no-regression (combined, advisory)
        continue-on-error: true
        run: |
          python scripts/check_coverage_delta.py --xml coverage-total.xml || true
      - name: Orchestrator package tests (advisory)
        continue-on-error: true
        run: |
          cd packages/orchestrator && pytest -q || true
      - name: LLM runtime package tests (advisory)
        continue-on-error: true
        run: |
          cd packages/llm && pytest -q || true
      - name: DSPy modules package tests (advisory)
        continue-on-error: true
        run: |
          cd packages/dspy && pytest -q || true
      - name: RAG splitter tests (advisory)
        continue-on-error: true
        run: |
          pytest -q infra/rag/tests || true
      - name: Research offline tests (advisory)
        continue-on-error: true
        run: |
          pytest -q scripts/research/tests || true
      - name: Build wheels (advisory)
        continue-on-error: true
        run: |
          python -m pip install --upgrade build
          python -m build packages/orchestrator || true
          python -m build packages/llm || true
          python -m build packages/dspy || true
      - name: Upload wheels
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: wheels_${{ matrix.python-version }}
          path: |
            packages/orchestrator/dist
            packages/llm/dist
            packages/dspy/dist
      - name: Coverage no-regression (advisory)
        continue-on-error: true
        run: |
          python scripts/check_coverage_delta.py || true
      - name: Repo size budget (advisory)
        continue-on-error: true
        run: |
          python scripts/size_budget.py || true
      - name: Bloat Check (advisory)
        continue-on-error: true
        run: |
          python3 scripts/prune_bloat.py --min-mb 25 > bloat_candidates.txt || true
          echo "Bloat candidates written to bloat_candidates.txt"
      - name: Upload bloat candidates
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bloat_candidates_${{ matrix.python-version }}
          path: bloat_candidates.txt
      - name: Determinism snapshots (advisory)
        continue-on-error: true
        run: |
          cd ISA_SuperApp && pytest -q tests/unit/test_snapshot_canonical_sample.py || true
      - name: Coherence audit (advisory)
        continue-on-error: true
        run: |
          python3 scripts/coherence_audit.py || true
      - name: Upload coherence audit artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coherence_audit_${{ matrix.python-version }}
          path: |
            coherence_graph.json
            orphans_and_dead_ends.md
            TERMS.md
            traceability_matrix.csv
            COHERENCE_SCORECARD.md
            contradiction_report.md
      - name: Memory coherence gate (enforced)
        run: |
          python scripts/memory_coherence_gate.py
      - name: Snapshot memory logs (artifact)
        continue-on-error: true
        run: |
          python - << 'PY'
          from ISA_SuperApp.src.memory.logs import MemoryEventLogger
          logger = MemoryEventLogger()
          n = logger.snapshot_to('docs/audit/memory_logs_snapshot.jsonl')
          print(f'snapshotted {n} memory events')
          PY
      - name: Upload memory logs snapshot
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: memory_logs
          path: docs/audit/memory_logs_snapshot.jsonl
      - name: Security — Bandit (advisory)
        continue-on-error: true
        run: |
          bandit -qq -r ISA_SuperApp/src || true
      - name: Security — pip-audit (advisory)
        continue-on-error: true
        run: |
          pip-audit || true
      - name: Complexity — Radon (report only)
        continue-on-error: true
        run: |
          radon cc -s -n D ISA_SuperApp/src || true
      - name: Deep checks — Semgrep (advisory, significance)
        if: steps.sig.outputs.significant == 'true'
        continue-on-error: true
        run: |
          pip install semgrep
          semgrep --config p/ci --error --timeout 120 --json | tee semgrep.json || true
      - name: Upload semgrep.json
        if: always() && steps.sig.outputs.significant == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: semgrep_${{ matrix.python-version }}
          path: semgrep.json
      - name: Docs build (advisory)
        continue-on-error: true
        run: |
          if [ -f ISA_SuperApp/mkdocs.yml ]; then cd ISA_SuperApp && mkdocs build -q || true; fi
      - name: Healthcheck (advisory)
        continue-on-error: true
        run: |
          make healthcheck || true
      - name: Upload healthcheck
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: healthcheck_${{ matrix.python-version }}
          path: docs/audit/healthcheck.md
      - name: Container build + smoke (advisory, significance)
        if: steps.sig.outputs.significant == 'true'
        continue-on-error: true
        run: |
          cd ISA_SuperApp
          docker build -t superapp:ci .
          docker run -d -p 8787:8787 --name superapp_ci superapp:ci
          echo 'Waiting for /metrics...'; for i in $(seq 1 20); do curl -fsS http://127.0.0.1:8787/metrics && break || sleep 2; done
          curl -fsS http://127.0.0.1:8787/metrics | head -n 5
          docker rm -f superapp_ci || true
      - name: Agent kill-switch (policy/agent-blocked)
        if: github.event_name == 'pull_request'
        run: |
          echo '${{ toJSON(github.event.pull_request.labels) }}' | grep -q 'policy/agent-blocked' && { echo 'Agent blocked by policy label'; exit 1; } || true
      - name: Waiver required for break-glass
        if: github.event_name == 'pull_request'
        run: |
          BODY='${{ github.event.pull_request.body }}'
          LABELS='${{ toJSON(github.event.pull_request.labels) }}'
          if echo "$LABELS" | grep -q 'break-glass'; then
            echo "$BODY" | grep -qi 'waiver: *true' || { echo 'Missing waiver: true in PR body for break-glass'; exit 1; }
          fi
      - name: Deep checks — Extended tests (advisory, significance)
        if: steps.sig.outputs.significant == 'true'
        continue-on-error: true
        run: |
          cd ISA_SuperApp && pytest -q --maxfail=1 --durations=10 || true
      - name: Save baselines on main
        if: github.ref == 'refs/heads/main'
        continue-on-error: true
        run: |
          python scripts/save_baselines.py || true
          # Also store combined coverage baseline
          if [ -f coverage-total.xml ]; then python - << 'PY'
          import json, xml.etree.ElementTree as ET
          from pathlib import Path
          root = ET.parse('coverage-total.xml').getroot()
          valid=float(root.attrib.get('lines-valid',0)); covered=float(root.attrib.get('lines-covered',0))
          pct=(covered/valid*100.0) if valid else 0.0
          p=Path('docs/audit/coverage_baseline.json'); p.parent.mkdir(parents=True, exist_ok=True)
          p.write_text(json.dumps({'coverage_pct':pct}, indent=2), encoding='utf-8')
          print('combined coverage baseline ->', p, f'({pct:.2f}%)')
          PY
          fi
      - name: Upload audit artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: audit_artifacts_${{ matrix.python-version }}
          path: |
            docs/audit/coverage_baseline.json
            docs/audit/size_baseline.json
            docs/audit/docs_ref_report.md
  secrets:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Gitleaks (advisory)
        uses: gitleaks/gitleaks-action@v2
        with:
          args: detect --no-git -v --redact
        continue-on-error: true
